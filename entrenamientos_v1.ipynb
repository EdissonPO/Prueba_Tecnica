{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialmente Entrenamos una regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación del modelo (escala original):\n",
      "MAE: 37.14\n",
      "RMSE: 76.00\n",
      "R² (log escala): 0.0853\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv(\"/Users/edissonpenagosospina/Downloads/dataSet.csv\")\n",
    "\n",
    "# Opcional: trabajar con una muestra más pequeña para pruebas rápidas\n",
    "#df_sample = df.sample(n=50000, random_state=42)\n",
    "\n",
    "# Separar features y target\n",
    "X = df.drop(columns=[\"log_amount\"])\n",
    "y = df[\"log_amount\"]\n",
    "\n",
    "# Dividir en entrenamiento y prueba (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar regresión lineal\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluación en escala original (revirtiendo log1p con expm1)\n",
    "y_test_original = np.expm1(y_test)\n",
    "y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "r2 = r2_score(y_test, y_pred)  # Este sí se evalúa en log escala\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Evaluación del modelo (escala original):\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² (log escala): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se prueba con random forest regressor debido a que la regresión lineal no es capaz de capturar la no linealidad de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación del modelo Random Forest (escala original):\n",
      "MAE: 13.35\n",
      "RMSE: 33.99\n",
      "R² (log escala): 0.8781\n",
      "Porcentaje de predicciones con error menor a $10: 66.77%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv(\"/Users/edissonpenagosospina/Downloads/dataSet.csv\")\n",
    "\n",
    "# Trabajar con una muestra más pequeña para pruebas\n",
    "df_sample = df.sample(7000000, random_state=42)\n",
    "\n",
    "# Separar features y target\n",
    "X = df_sample.drop(columns=[\"log_amount\"])\n",
    "y = df_sample[\"log_amount\"]\n",
    "\n",
    "# Dividir en entrenamiento y prueba (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluación en escala original\n",
    "y_test_original = np.expm1(y_test)\n",
    "y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Evaluación del modelo Random Forest (escala original):\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² (log escala): {r2:.4f}\")\n",
    "\n",
    "# Error absoluto en escala original\n",
    "errors = np.abs(np.expm1(y_test) - np.expm1(y_pred))\n",
    "\n",
    "# Porcentaje de predicciones con error < $10\n",
    "accuracy_10usd = np.mean(errors < 10) * 100\n",
    "\n",
    "print(f\"Porcentaje de predicciones con error menor a $10: {accuracy_10usd:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature  importance\n",
      "14                 mcc    0.347501\n",
      "10         merchant_id    0.126722\n",
      "4     transaction_hour    0.120199\n",
      "36   per_capita_income    0.052018\n",
      "5            client_id    0.030528\n",
      "38          total_debt    0.024597\n",
      "34            latitude    0.023978\n",
      "39        credit_score    0.023956\n",
      "37       yearly_income    0.022821\n",
      "35           longitude    0.022719\n",
      "2      transaction_day    0.020784\n",
      "29      retirement_age    0.015675\n",
      "1    transaction_month    0.015003\n",
      "31         birth_month    0.014333\n",
      "11  merchant_city_freq    0.013872\n",
      "25        credit_limit    0.013157\n",
      "30          birth_year    0.013058\n",
      "13                 zip    0.012938\n",
      "0     transaction_year    0.012576\n",
      "28         current_age    0.012001\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener la importancia de las variables\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Crear un DataFrame ordenado por importancia\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Mostrar las 20 más importantes\n",
    "print(importances_df.head(20))\n",
    "\n",
    "# Gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importances_df.head(20)['feature'], importances_df.head(20)['importance'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.title(\"Top 20 variables más importantes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora voy a reducir el dataSet a las 30 columnas mas relevantes en el modelo para hacerlo mas lijero y poder entrenar el modelo con todos los registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feature = importances_df['feature'].head(30).reset_index(drop=True).to_list()\n",
    "list_feature.append('log_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mcc',\n",
       " 'merchant_id',\n",
       " 'transaction_hour',\n",
       " 'per_capita_income',\n",
       " 'client_id',\n",
       " 'total_debt',\n",
       " 'latitude',\n",
       " 'credit_score',\n",
       " 'yearly_income',\n",
       " 'longitude',\n",
       " 'transaction_day',\n",
       " 'retirement_age',\n",
       " 'transaction_month',\n",
       " 'birth_month',\n",
       " 'merchant_city_freq',\n",
       " 'credit_limit',\n",
       " 'birth_year',\n",
       " 'zip',\n",
       " 'transaction_year',\n",
       " 'current_age',\n",
       " 'transaction_weekday',\n",
       " 'num_credit_cards',\n",
       " 'merchant_state_freq',\n",
       " 'card_id',\n",
       " 'acct_open_date_year',\n",
       " 'card_type_Credit',\n",
       " 'acct_open_date_month',\n",
       " 'gender_Female',\n",
       " 'gender_Male',\n",
       " 'num_cards_issued',\n",
       " 'log_amount']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>transaction_month</th>\n",
       "      <th>transaction_day</th>\n",
       "      <th>transaction_weekday</th>\n",
       "      <th>transaction_hour</th>\n",
       "      <th>client_id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>merchant_city_freq</th>\n",
       "      <th>merchant_state_freq</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>per_capita_income</th>\n",
       "      <th>yearly_income</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>num_credit_cards</th>\n",
       "      <th>log_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>561</td>\n",
       "      <td>4575</td>\n",
       "      <td>67570</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>1.211950</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.80</td>\n",
       "      <td>-91.12</td>\n",
       "      <td>18076</td>\n",
       "      <td>36853</td>\n",
       "      <td>112139</td>\n",
       "      <td>834</td>\n",
       "      <td>5</td>\n",
       "      <td>2.745346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1129</td>\n",
       "      <td>102</td>\n",
       "      <td>27092</td>\n",
       "      <td>0.047468</td>\n",
       "      <td>10.725208</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.18</td>\n",
       "      <td>-117.29</td>\n",
       "      <td>16894</td>\n",
       "      <td>34449</td>\n",
       "      <td>36540</td>\n",
       "      <td>686</td>\n",
       "      <td>3</td>\n",
       "      <td>4.394449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>430</td>\n",
       "      <td>2860</td>\n",
       "      <td>27092</td>\n",
       "      <td>0.129446</td>\n",
       "      <td>2.348354</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41.42</td>\n",
       "      <td>-87.35</td>\n",
       "      <td>26168</td>\n",
       "      <td>53350</td>\n",
       "      <td>128676</td>\n",
       "      <td>685</td>\n",
       "      <td>5</td>\n",
       "      <td>5.303305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>848</td>\n",
       "      <td>3915</td>\n",
       "      <td>13051</td>\n",
       "      <td>0.020404</td>\n",
       "      <td>1.456315</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.86</td>\n",
       "      <td>-76.60</td>\n",
       "      <td>33529</td>\n",
       "      <td>68362</td>\n",
       "      <td>96182</td>\n",
       "      <td>711</td>\n",
       "      <td>2</td>\n",
       "      <td>3.858833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1807</td>\n",
       "      <td>165</td>\n",
       "      <td>20519</td>\n",
       "      <td>0.393584</td>\n",
       "      <td>6.444577</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.84</td>\n",
       "      <td>-73.87</td>\n",
       "      <td>25537</td>\n",
       "      <td>52065</td>\n",
       "      <td>98613</td>\n",
       "      <td>828</td>\n",
       "      <td>5</td>\n",
       "      <td>1.759581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645861</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1718</td>\n",
       "      <td>2379</td>\n",
       "      <td>86438</td>\n",
       "      <td>0.066865</td>\n",
       "      <td>10.725208</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.02</td>\n",
       "      <td>-117.89</td>\n",
       "      <td>22681</td>\n",
       "      <td>33483</td>\n",
       "      <td>196</td>\n",
       "      <td>698</td>\n",
       "      <td>5</td>\n",
       "      <td>0.746688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645862</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1766</td>\n",
       "      <td>2066</td>\n",
       "      <td>39261</td>\n",
       "      <td>11.751916</td>\n",
       "      <td>11.751916</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.06</td>\n",
       "      <td>-87.96</td>\n",
       "      <td>9995</td>\n",
       "      <td>20377</td>\n",
       "      <td>12092</td>\n",
       "      <td>789</td>\n",
       "      <td>4</td>\n",
       "      <td>2.624669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645863</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>199</td>\n",
       "      <td>1031</td>\n",
       "      <td>2925</td>\n",
       "      <td>0.094740</td>\n",
       "      <td>7.592165</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.10</td>\n",
       "      <td>-96.66</td>\n",
       "      <td>32580</td>\n",
       "      <td>78329</td>\n",
       "      <td>40161</td>\n",
       "      <td>720</td>\n",
       "      <td>3</td>\n",
       "      <td>3.724247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645864</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1986</td>\n",
       "      <td>5443</td>\n",
       "      <td>46284</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>10.725208</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.68</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>23752</td>\n",
       "      <td>48430</td>\n",
       "      <td>62384</td>\n",
       "      <td>716</td>\n",
       "      <td>2</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645865</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>489</td>\n",
       "      <td>5697</td>\n",
       "      <td>24658</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>2.139718</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.87</td>\n",
       "      <td>-97.59</td>\n",
       "      <td>18024</td>\n",
       "      <td>36753</td>\n",
       "      <td>33657</td>\n",
       "      <td>684</td>\n",
       "      <td>4</td>\n",
       "      <td>2.630449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12645866 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          transaction_year  transaction_month  transaction_day  \\\n",
       "0                     2010                  1                1   \n",
       "1                     2010                  1                1   \n",
       "2                     2010                  1                1   \n",
       "3                     2010                  1                1   \n",
       "4                     2010                  1                1   \n",
       "...                    ...                ...              ...   \n",
       "12645861              2019                 10               31   \n",
       "12645862              2019                 10               31   \n",
       "12645863              2019                 10               31   \n",
       "12645864              2019                 10               31   \n",
       "12645865              2019                 10               31   \n",
       "\n",
       "          transaction_weekday  transaction_hour  client_id  card_id  \\\n",
       "0                           4                 0        561     4575   \n",
       "1                           4                 0       1129      102   \n",
       "2                           4                 0        430     2860   \n",
       "3                           4                 0        848     3915   \n",
       "4                           4                 0       1807      165   \n",
       "...                       ...               ...        ...      ...   \n",
       "12645861                    3                23       1718     2379   \n",
       "12645862                    3                23       1766     2066   \n",
       "12645863                    3                23        199     1031   \n",
       "12645864                    3                23       1986     5443   \n",
       "12645865                    3                23        489     5697   \n",
       "\n",
       "          merchant_id  merchant_city_freq  merchant_state_freq  ...  \\\n",
       "0               67570            0.002653             1.211950  ...   \n",
       "1               27092            0.047468            10.725208  ...   \n",
       "2               27092            0.129446             2.348354  ...   \n",
       "3               13051            0.020404             1.456315  ...   \n",
       "4               20519            0.393584             6.444577  ...   \n",
       "...               ...                 ...                  ...  ...   \n",
       "12645861        86438            0.066865            10.725208  ...   \n",
       "12645862        39261           11.751916            11.751916  ...   \n",
       "12645863         2925            0.094740             7.592165  ...   \n",
       "12645864        46284            0.041395            10.725208  ...   \n",
       "12645865        24658            0.001886             2.139718  ...   \n",
       "\n",
       "          gender_Female  gender_Male  latitude  longitude  per_capita_income  \\\n",
       "0                     0            1     40.80     -91.12              18076   \n",
       "1                     0            1     33.18    -117.29              16894   \n",
       "2                     1            0     41.42     -87.35              26168   \n",
       "3                     0            1     38.86     -76.60              33529   \n",
       "4                     1            0     40.84     -73.87              25537   \n",
       "...                 ...          ...       ...        ...                ...   \n",
       "12645861              1            0     34.02    -117.89              22681   \n",
       "12645862              0            1     43.06     -87.96               9995   \n",
       "12645863              1            0     33.10     -96.66              32580   \n",
       "12645864              1            0     37.68    -122.43              23752   \n",
       "12645865              0            1     40.87     -97.59              18024   \n",
       "\n",
       "          yearly_income  total_debt  credit_score  num_credit_cards  \\\n",
       "0                 36853      112139           834                 5   \n",
       "1                 34449       36540           686                 3   \n",
       "2                 53350      128676           685                 5   \n",
       "3                 68362       96182           711                 2   \n",
       "4                 52065       98613           828                 5   \n",
       "...                 ...         ...           ...               ...   \n",
       "12645861          33483         196           698                 5   \n",
       "12645862          20377       12092           789                 4   \n",
       "12645863          78329       40161           720                 3   \n",
       "12645864          48430       62384           716                 2   \n",
       "12645865          36753       33657           684                 4   \n",
       "\n",
       "          log_amount  \n",
       "0           2.745346  \n",
       "1           4.394449  \n",
       "2           5.303305  \n",
       "3           3.858833  \n",
       "4           1.759581  \n",
       "...              ...  \n",
       "12645861    0.746688  \n",
       "12645862    2.624669  \n",
       "12645863    3.724247  \n",
       "12645864    1.609438  \n",
       "12645865    2.630449  \n",
       "\n",
       "[12645866 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, df.columns.isin(list_feature)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv(\"/Users/edissonpenagosospina/Downloads/dataSet.csv\")\n",
    "\n",
    "list_feature = ['mcc', 'merchant_id', 'transaction_hour', 'per_capita_income', 'client_id', 'total_debt',\n",
    " 'latitude', 'credit_score', 'yearly_income', 'longitude', 'transaction_day', 'retirement_age',\n",
    " 'transaction_month', 'birth_month', 'merchant_city_freq', 'credit_limit', 'birth_year', 'zip',\n",
    " 'transaction_year', 'current_age', 'log_amount']\n",
    "\n",
    "df_light = df.loc[:, df.columns.isin(list_feature)]\n",
    "\n",
    "\n",
    "# Trabajar con una muestra más pequeña para pruebas\n",
    "df_sample = df.sample(n=9000000, random_state=42)\n",
    "\n",
    "# Separar features y target\n",
    "X = df_sample.drop(columns=[\"log_amount\"])\n",
    "y = df_sample[\"log_amount\"]\n",
    "\n",
    "# Dividir en entrenamiento y prueba (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluación en escala original\n",
    "y_test_original = np.expm1(y_test)\n",
    "y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Evaluación del modelo Random Forest (escala original):\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² (log escala): {r2:.4f}\")\n",
    "\n",
    "# Error absoluto en escala original\n",
    "errors = np.abs(np.expm1(y_test) - np.expm1(y_pred))\n",
    "\n",
    "# Porcentaje de predicciones con error < $10\n",
    "accuracy_10usd = np.mean(errors < 10) * 100\n",
    "\n",
    "print(f\"Porcentaje de predicciones con error menor a $10: {accuracy_10usd:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se prueba el modelo lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demensionalidad del dataFrame (12645866, 42)\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3604\n",
      "[LightGBM] [Info] Number of data points in the train set: 10116692, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.294205\n",
      "📊 Evaluación del modelo LightGBM:\n",
      "MAE (escala original): 24.42\n",
      "RMSE (escala original): 52.03\n",
      "R² (log escala): 0.6132\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (Opcional) Para solucionar problemas con libomp en macOS\n",
    "#os.environ['DYLD_LIBRARY_PATH'] = '/opt/homebrew/opt/libomp/lib'\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(\"/Users/edissonpenagosospina/Downloads/dataSet.csv\")\n",
    "\n",
    "# Usar una muestra para entrenamiento rápido (ajusta n si quieres más datos)\n",
    "# df_sample = df.sample(n=50000, random_state=42)\n",
    "print(\"demensionalidad del dataFrame\" , df.shape)\n",
    "# Separar features y target\n",
    "X = df.drop(columns=[\"log_amount\"])\n",
    "y = df[\"log_amount\"]\n",
    "\n",
    "# Dividir en entrenamiento y prueba (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo LightGBM\n",
    "model = LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluación en escala original (invirtiendo log1p → expm1)\n",
    "y_test_original = np.expm1(y_test)\n",
    "y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "r2 = r2_score(y_test, y_pred)  # En log escala\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"📊 Evaluación del modelo LightGBM:\")\n",
    "print(f\"MAE (escala original): {mae:.2f}\")\n",
    "print(f\"RMSE (escala original): {rmse:.2f}\")\n",
    "print(f\"R² (log escala): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.299256\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 53333, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.295985\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 53334, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297153\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3582\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.297465\n",
      "🔍 Mejores hiperparámetros encontrados:\n",
      "{'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 50}\n",
      "\n",
      "📊 Evaluación del mejor modelo (tuneado):\n",
      "MAE: 22.73\n",
      "RMSE: 51.80\n",
      "R² (log escala): 0.6714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Tomar una muestra más manejable para tuning\n",
    "df_sample = df.sample(n=100000, random_state=42)\n",
    "X = df_sample.drop(columns=[\"log_amount\"])\n",
    "y = df_sample[\"log_amount\"]\n",
    "\n",
    "# Dividir\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el modelo base\n",
    "lgb_model = LGBMRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Definir el grid de hiperparámetros\n",
    "param_grid = {\n",
    "    \"num_leaves\": [31, 50],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [-1, 10]\n",
    "}\n",
    "\n",
    "# Ejecutar Grid Search\n",
    "grid = GridSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",  # se puede cambiar por \"neg_root_mean_squared_error\"\n",
    "    cv=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores parámetros encontrados\n",
    "print(\"🔍 Mejores hiperparámetros encontrados:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Escala original\n",
    "y_test_original = np.expm1(y_test)\n",
    "y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n📊 Evaluación del mejor modelo (tuneado):\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² (log escala): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Dataset cargado: (12645866, 42)\n",
      "🚀 Entrenando modelo final con todos los datos...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.224245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3608\n",
      "[LightGBM] [Info] Number of data points in the train set: 12645866, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 3.294010\n",
      "\n",
      "📊 Evaluación del modelo LightGBM (entrenado con todo el dataset):\n",
      "MAE: 22.23\n",
      "RMSE: 48.96\n",
      "R² (log escala): 0.6905\n",
      "✅ Porcentaje de predicciones con error menor a $10: 49.19%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import os\n",
    "\n",
    "# (Solo si estás en Mac y necesitas libomp)\n",
    "# os.environ['DYLD_LIBRARY_PATH'] = '/opt/homebrew/opt/libomp/lib'\n",
    "\n",
    "# Cargar el dataset completo\n",
    "df = pd.read_csv(\"/Users/edissonpenagosospina/Downloads/dataSet.csv\")\n",
    "print(f\"📦 Dataset cargado: {df.shape}\")\n",
    "\n",
    "# Separar features y variable objetivo\n",
    "X = df.drop(columns=[\"log_amount\"])\n",
    "y = df[\"log_amount\"]\n",
    "\n",
    "# Hiperparámetros óptimos encontrados\n",
    "best_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": -1,\n",
    "    \"n_estimators\": 200,\n",
    "    \"num_leaves\": 50\n",
    "}\n",
    "\n",
    "# Inicializar modelo final\n",
    "final_model = LGBMRegressor(\n",
    "    **best_params,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"🚀 Entrenando modelo final con todos los datos...\")\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Evaluar el modelo sobre una muestra aleatoria del 5%\n",
    "X_sample = X.sample(frac=0.05, random_state=42)\n",
    "y_sample = y.loc[X_sample.index]\n",
    "y_pred = final_model.predict(X_sample)\n",
    "\n",
    "# Volver a la escala original\n",
    "y_true_original = np.expm1(y_sample)\n",
    "y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "# Métricas\n",
    "mae = mean_absolute_error(y_true_original, y_pred_original)\n",
    "rmse = np.sqrt(mean_squared_error(y_true_original, y_pred_original))\n",
    "r2 = r2_score(y_sample, y_pred)\n",
    "\n",
    "print(\"\\n📊 Evaluación del modelo LightGBM (entrenado con todo el dataset):\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² (log escala): {r2:.4f}\")\n",
    "\n",
    "# Pasar a escala original\n",
    "y_true_original = np.expm1(y_sample)\n",
    "y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "# Calcular el error absoluto\n",
    "errors = np.abs(y_true_original - y_pred_original)\n",
    "\n",
    "# Calcular el porcentaje con error < $10\n",
    "accuracy_10usd = np.mean(errors < 10) * 100\n",
    "\n",
    "print(f\"✅ Porcentaje de predicciones con error menor a $10: {accuracy_10usd:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se concluye que la mejor opcion es el random forest teniendo en cuenta que tuvo los mejores resultados entrenandolo solo con la mitad de los datos debido a que no se cuenta con el poder de computo para hacerlo con el total del dataSet\n",
    "\n",
    "Este puede mejorar ajustando los hiperParametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Es muy relevante para entender el comportamiento de los clientes lo que mas influye en el mondo que gastan: se listan las primeras cinco variables mas importante:\n",
    "\n",
    "- mcc\n",
    "- merchant_id\n",
    "- transaction_hour\n",
    "- per_capita_income\n",
    "- total_debt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
